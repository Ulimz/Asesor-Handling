"""
Script de migraci√≥n para a√±adir metadata a chunks existentes.
VERSI√ìN H√çBRIDA - Combina estabilidad del experto con descriptividad mejorada.

Ejecutar: python backend/scripts/migrate_metadata.py
"""
import os
import sys
import hashlib
import re
from datetime import datetime

backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, backend_dir)

from app.db.database import SessionLocal
from app.db.models import DocumentChunk, LegalDocument
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def generate_version_hash(document: LegalDocument, year: int) -> str:
    """
    ‚úÖ DEL EXPERTO: Hash estable usando document.id
    """
    title = document.title or "unknown"
    base = f"{document.id}_{title}_{year}"
    return hashlib.md5(base.encode()).hexdigest()[:8]


def generate_doc_id(document: LegalDocument, year: int) -> str:
    """
    ‚úÖ H√çBRIDO: doc_id descriptivo pero estable
    Usa company + slug del t√≠tulo + year
    """
    company = document.company or "general"
    title = document.title or "unknown"
    # Crear slug del t√≠tulo
    title_slug = re.sub(r'[^a-z0-9]+', '_', title.lower())[:30]
    # ‚úÖ MEJORA: Strip underscores al inicio/final
    title_slug = title_slug.strip("_")
    return f"{company}_{title_slug}_{year}"


def infer_chunk_type(chunk: DocumentChunk) -> str:
    """
    ‚úÖ MEJORADO: Inferencia robusta de tablas
    """
    content_lower = (chunk.content or "").lower()
    article_ref = (chunk.article_ref or "").lower()

    # Tablas - detecci√≥n mejorada
    table_keywords = [
        'tabla salarial', 'tablas salariales',
        'retribuci√≥n', 'retribuciones',
        'salario', 'anexo', 'tabla'
    ]
    
    if 'anexo' in article_ref:
        if any(kw in content_lower for kw in ['retribu', 'salario', 'plus', 'nivel']):
            return 'table'
    
    if any(kw in content_lower for kw in table_keywords):
        return 'table'

    # Art√≠culos
    if 'art√≠culo' in article_ref or 'art.' in article_ref:
        return 'article'

    # Regulaciones
    if any(kw in content_lower for kw in ['r√©gimen disciplinario', 'faltas y sanciones']):
        return 'regulation'

    return 'text'


def infer_intents(chunk: DocumentChunk, chunk_type: str) -> list:
    """
    ‚úÖ MEJORADO: Inferencia con fallback SALARY para tablas
    """
    content_lower = (chunk.content or "").lower()
    intents = []

    # SALARY
    salary_keywords = [
        'salario', 'retribuci√≥n', 'tabla salarial', 
        'plus', 'paga extra', 'retribu'
    ]
    if any(kw in content_lower for kw in salary_keywords):
        intents.append('SALARY')

    # LEAVE
    leave_keywords = [
        'permiso', 'vacaciones', 'licencia', 
        'parentesco', 'ausencia'
    ]
    if any(kw in content_lower for kw in leave_keywords):
        intents.append('LEAVE')

    # DISMISSAL
    dismissal_keywords = [
        'despido', 'sanci√≥n', 'disciplinario', 'extinci√≥n'
    ]
    if any(kw in content_lower for kw in dismissal_keywords):
        intents.append('DISMISSAL')

    # ‚úÖ Fallback SALARY para tablas
    if chunk_type == 'table' and 'SALARY' not in intents:
        intents.append('SALARY')
        logger.debug(f"Chunk {chunk.id}: A√±adido SALARY (tabla sin keywords)")

    return intents if intents else ['GENERAL']


def migrate_chunk_metadata(chunk: DocumentChunk, document: LegalDocument) -> dict:
    """
    ‚úÖ H√çBRIDO: Metadata completa con mejores pr√°cticas
    """
    chunk_type = infer_chunk_type(chunk)
    intents = infer_intents(chunk, chunk_type)

    # Extraer a√±o
    year = 2025
    if document.title:
        year_match = re.search(r'20\d{2}', document.title)
        if year_match:
            year = int(year_match.group(0))

    # ‚úÖ DEL EXPERTO: version_hash estable
    version_hash = generate_version_hash(document, year)

    # ‚úÖ H√çBRIDO: doc_id descriptivo
    doc_id = generate_doc_id(document, year)

    # Extraer art√≠culo
    article_num = None
    if chunk.article_ref:
        art_match = re.search(r'(\d+)', chunk.article_ref)
        if art_match:
            article_num = int(art_match.group(1))

    return {
        "doc_id": doc_id,
        "company": document.company or "general",
        "intent": intents,
        "type": chunk_type,
        "year": year,
        "source": "convenio" if (document.title and "convenio" in document.title.lower()) else "estatuto",
        "article": article_num,
        "version_hash": version_hash,
        "chunk_size": len(chunk.content or ""),
        "is_primary": chunk_type in ['table', 'article'],
    }


def main():
    db = SessionLocal()

    try:
        logger.info("üîÑ Iniciando migraci√≥n H√çBRIDA de metadata...")

        chunks = db.query(DocumentChunk).all()
        total = len(chunks)

        logger.info(f"üìä Total de chunks: {total}")

        migrated = 0
        skipped = 0

        for i, chunk in enumerate(chunks, 1):
            if not hasattr(chunk, 'document') or chunk.document is None:
                logger.warning(f"‚ö†Ô∏è  Chunk {chunk.id} sin documento, saltando...")
                skipped += 1
                continue

            # Generar metadata
            metadata = migrate_chunk_metadata(chunk, chunk.document)

            # ‚úÖ DEL EXPERTO: Actualizar columna Y metadata
            chunk.chunk_metadata = metadata
            chunk.doc_id = metadata["doc_id"]
            
            migrated += 1

            if i % 100 == 0:
                db.commit()
                logger.info(f"‚úÖ Procesados {i}/{total}...")

        db.commit()
        logger.info(f"\n‚úÖ Migraci√≥n completada:")
        logger.info(f"   - Migrados: {migrated}")
        logger.info(f"   - Saltados: {skipped}")

        # ‚úÖ MEJORADO: Estad√≠sticas detalladas
        logger.info("\nüìä Estad√≠sticas por tipo:")
        for chunk_type in ['table', 'article', 'regulation', 'text']:
            count = db.query(DocumentChunk).filter(
                DocumentChunk.chunk_metadata['type'].astext == chunk_type
            ).count()
            logger.info(f"   - {chunk_type}: {count}")

        logger.info("\nüìä Estad√≠sticas por intent:")
        for intent in ['SALARY', 'LEAVE', 'DISMISSAL', 'GENERAL']:
            count = db.query(DocumentChunk).filter(
                DocumentChunk.chunk_metadata['intent'].contains([intent])
            ).count()
            logger.info(f"   - {intent}: {count}")

    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)
        db.rollback()
        raise

    finally:
        db.close()


if __name__ == "__main__":
    main()
